version: 2.1

# Only the build job uses Nx Cloud; other jobs consume its dist via workspace
parameters:
  # Workflow triggers
  run_all_tests:
    type: boolean
    default: false
  run_pr_tests:
    type: boolean
    default: false
  run_file_tests:
    type: string
    default: ""
  run_flaky_tests:
    type: boolean
    default: false
  run_lint_only:
    type: boolean
    default: false
  run_build_only:
    type: boolean
    default: false
  run_plan_shards:
    type: boolean
    default: false
  run_rerun_failed:
    type: boolean
    default: false

  # E2E configuration
  e2e_parallelism:
    type: integer
    default: 20
  e2e_retries:
    type: integer
    default: 0

  # Rerun-failed configuration
  rerun_failed_history:
    type: integer
    default: 1
  rerun_failed_mode:
    type: string
    default: "most-recent"
  rerun_failed_workflow:
    type: string
    default: "web,run_file_tests,run_pr_tests,run_flaky_tests"

  # Resource sizing
  resource_class:
    type: enum
    enum: ["small", "medium", "medium+", "large", "xlarge", "2xlarge"]
    default: "small"

orbs:
  browser-tools: circleci/browser-tools@1.5.2

commands:
  nx-build-with-fallback:
    description: "Run Nx build with Cloud fallback"
    parameters:
      target:
        type: string
        description: "Nx build target (e.g., 'build', 'remix-ide')"
      config:
        type: string
        default: ""
        description: "Configuration flag (e.g., '--configuration=production')"
      memory:
        type: string
        default: "4096"
        description: "Max memory in MB for Node.js"
      fallback_command:
        type: string
        default: ""
        description: "Custom fallback command (if empty, uses yarn build with skip-cache)"
    steps:
      - run:
          name: Nx build << parameters.target >> (Cloud with fallback)
          command: |
            CONFIG_FLAG="<< parameters.config >>"
            MEMORY="<< parameters.memory >>"
            TARGET="<< parameters.target >>"
            FALLBACK="<< parameters.fallback_command >>"
            
            if [ -n "${NX_CLOUD_ACCESS_TOKEN:-}" ]; then
              echo "Attempting Nx Cloud build for $TARGET..."
              if NX_VERBOSE_LOGGING=1 node --max-old-space-size=$MEMORY ./node_modules/.bin/nx build $TARGET $CONFIG_FLAG --cloud --verbose; then
                echo "‚úì Nx Cloud build succeeded"
              else
                echo "‚ö† Nx Cloud build failed (out of credits or unavailable)"
                echo "‚Üí Falling back to local build..."
                if [ -n "$FALLBACK" ]; then
                  eval "$FALLBACK"
                elif [ "$CONFIG_FLAG" = "--configuration=production" ]; then
                  NODE_ENV=production yarn nx build $TARGET $CONFIG_FLAG
                else
                  NX_VERBOSE_LOGGING=1 yarn build --skip-nx-cache
                fi
              fi
            else
              echo "No NX_CLOUD_ACCESS_TOKEN; running local build"
              if [ -n "$FALLBACK" ]; then
                eval "$FALLBACK"
              elif [ "$CONFIG_FLAG" = "--configuration=production" ]; then
                NODE_ENV=production yarn nx build $TARGET $CONFIG_FLAG
              else
                NX_VERBOSE_LOGGING=1 yarn build --skip-nx-cache
              fi
            fi

jobs:
  build:
    docker:
      - image: cimg/node:20.19.0-browsers
    resource_class: medium+
    working_directory: ~/remix-project
    steps:
      - checkout
      - restore_cache:
          keys:
            - v1-deps-{{ checksum "yarn.lock" }}
      - run: yarn
      - save_cache:
          key: v1-deps-{{ checksum "yarn.lock" }}
          paths:
            - node_modules
      - nx-build-with-fallback:
          target: "remix-ide"
          fallback_command: "yarn build"
      - run:
          name: Inject E2E test configuration
          command: yarn inject-e2e-config
      - run:
          name: Compile E2E tests once
          command: yarn run build:e2e
      - run:
          name: Compute soljson version list
          command: grep -ir "[0-9]+commit" apps/* libs/* --include \*.ts --include \*.tsx --include \*.json > soljson-versions.txt || true
      - run:
          name: Download solc wasm assets (once)
          command: yarn run downloadsolc_assets_e2e
      - run:
          name: Package dist for workspace
          command: |
            set -e
            tar -cf remix-dist.tar dist/apps/remix-ide dist/apps/remix-ide-e2e dist/apps/remix-ide/assets/js/soljson 2>/dev/null || true
            gzip -1 remix-dist.tar
      - persist_to_workspace:
          root: .
          paths:
            - remix-dist.tar.gz

  build-plugin:
    docker:
      - image: cimg/node:20.19.0-browsers
    resource_class: << pipeline.parameters.resource_class >>
    working_directory: ~/remix-project
    parameters:
      plugin:
        type: string
    steps:
      - checkout
      - restore_cache:
          keys:
            - v1-deps-{{ checksum "yarn.lock" }}
      - run: yarn
      - save_cache:
          key: v1-deps-{{ checksum "yarn.lock" }}
          paths:
            - node_modules
      - nx-build-with-fallback:
          target: "<< parameters.plugin >>"
          config: "--configuration=production"

  lint:
    docker:
      - image: cimg/node:20.19.0-browsers
    resource_class: << pipeline.parameters.resource_class >>
    working_directory: ~/remix-project
    steps:
      - checkout
      - restore_cache:
          keys:
            - v1-deps-{{ checksum "yarn.lock" }}
      - run: yarn
      - run: yarn nx graph --file=./projects.json
      - run:
          name: Remix Libs Linting
          command: node ./apps/remix-ide/ci/lint-targets.js

  remix-libs:
    docker:
      - image: cimg/node:20.19.0-browsers
    resource_class: << pipeline.parameters.resource_class >>
    working_directory: ~/remix-project
    steps:
      - checkout
      - restore_cache:
          keys:
            - v1-deps-{{ checksum "yarn.lock" }}
      - run: yarn --version
      - run: yarn
      - run: yarn build:libs
      - run: cd dist/libs/remix-tests && yarn
      - run: cd dist/libs/remix-tests && yarn add @remix-project/remix-url-resolver ../../libs/remix-url-resolver
      - run: cd dist/libs/remix-tests && yarn add @remix-project/remix-lib ../../libs/remix-lib
      - run: cd dist/libs/remix-tests && yarn add @remix-project/remix-solidity ../../libs/remix-solidity
      - run: cd dist/libs/remix-tests && yarn add @remix-project/remix-simulator ../../libs/remix-simulator
      - run: cd dist/libs/remix-tests && ./bin/remix-tests ./../../../libs/remix-tests/tests/examples_0/assert_ok_test.sol
      - run: node dist/libs/remix-tests/bin/remix-tests ./libs/remix-tests/tests/examples_0/assert_ok_test.sol
      - run: yarn run test:libs

  check-flaky-or-pr-tests:
    docker:
      - image: cimg/node:24.3.0
    resource_class: << pipeline.parameters.resource_class >>
    working_directory: ~/remix-project
    parameters:
      pattern:
        type: string
    steps:
      - checkout
      - run: node apps/remix-ide-e2e/src/buildGroupTests.js
      - run:
          name: Check for enabled tests matching tag
          command: |
            PATTERN="<< parameters.pattern >>"
            if [ -z "$PATTERN" ]; then
              echo "‚ùå Tag parameter is empty!"
              exit 2
            fi
            echo "üîç Searching for enabled tests with .$PATTERN extension..."
            if grep -IRiL "'@disabled': \?true" "./apps/remix-ide-e2e/src/tests" | grep "${PATTERN}"; then
              echo "‚úÖ Found enabled .$PATTERN tests."
              exit 0
            else
              echo "‚ö†Ô∏è No enabled .$PATTERN tests found. Skipping workflow."
              exit 1
            fi

  remix-ide-browser:
    docker:
      - image: cimg/node:20.19.0-browsers
    resource_class: << pipeline.parameters.resource_class >>
    working_directory: ~/remix-project
    parameters:
      browser:
        type: string
      script:
        type: string
      scriptparameter:
        type: string
      job:
        type: string
      jobsize:
        type: string
      shard_index:
        type: integer
        default: 0
      vertical_mode:
        type: boolean
        default: false
      parallelism:
        type: integer
        default: 1
      skip_timings:
        type: boolean
        default: false
    parallelism: << parameters.parallelism >>
    steps:
      - checkout
      - attach_workspace:
          at: ~/remix-project
      - restore_cache:
          keys:
            - v1-deps-{{ checksum "yarn.lock" }}
      - run: yarn
      - run:
          name: Unpack dist from workspace
          command: |
            if [ -f remix-dist.tar.gz ]; then
              tar -xzf remix-dist.tar.gz
            fi
      - run: ls -la ./dist/apps/remix-ide/assets/js || true
      - browser-tools/install-browser-tools:
          install-chrome: true
          install-chromedriver: false
          install-firefox: false
          install-geckodriver: false
      - run: yarn install_webdriver
      - run: google-chrome --version
      - when:
          condition:
            not: << parameters.skip_timings >>
          steps:
            - run:
                name: Fetch CircleCI timings snapshot (best effort)
                command: |
                  if [ -n "${CIRCLECI_TOKEN:-}" ]; then
                    echo "Fetching timings for branch ${CIRCLE_BRANCH:-all}..."
                    yarn ci:timings --slug gh/remix-project-org/remix-project --workflow web --branch "${CIRCLE_BRANCH:-}" --limit 30 --json timings-current.json || true
                  else
                    echo "CIRCLECI_TOKEN not set; skipping timings fetch. Self-split will fall back to median weights."
                  fi
      - run:
          name: Run E2E shard (self-split)
          command: |
            # If running in vertical mode (parallelism=1 matrix), force shard env; otherwise let CircleCI provide them
            if [ "<< parameters.vertical_mode >>" = "true" ]; then
              export CIRCLE_NODE_TOTAL=<< pipeline.parameters.e2e_parallelism >>
              export CIRCLE_NODE_INDEX=<< parameters.shard_index >>
            fi
            E2E_RETRIES=<< pipeline.parameters.e2e_retries >> SELF_SPLIT=1 TIMINGS_JSON=timings-current.json \
            ./apps/remix-ide/ci/<< parameters.script >> << parameters.browser >> << parameters.jobsize >> << parameters.job >> << parameters.scriptparameter >>
      - store_test_results:
          path: ./reports/tests
      - store_artifacts:
          path: ./reports/screenshots
      - store_artifacts:
          path: ./reports/shards
      - store_artifacts:
          path: ./timings-current.json

  plan-e2e-shards:
    docker:
      - image: cimg/node:20.19.0-browsers
    resource_class: << pipeline.parameters.resource_class >>
    working_directory: ~/remix-project
    parameters:
      shards:
        type: integer
        default: 20
    steps:
      - checkout
      - restore_cache:
          keys:
            - v1-deps-{{ checksum "yarn.lock" }}
      - run: yarn
      - run:
          name: Compile E2E tests (generate groups)
          command: yarn run build:e2e
      - run:
          name: Fetch CircleCI timings snapshot (best effort)
          command: |
            if [ -n "${CIRCLECI_TOKEN:-}" ]; then
              echo "Fetching timings for branch ${CIRCLE_BRANCH:-all}..."
              yarn ci:timings --slug gh/remix-project-org/remix-project --workflow web --branch "${CIRCLE_BRANCH:-}" --limit 30 --json timings-current.json || true
            else
              echo "CIRCLECI_TOKEN not set; planning will use median default weights."
            fi
      - run:
          name: Compute shard planning overview (no test execution)
          command: |
            set -e
            mkdir -p reports/shards
            echo "Enumerating enabled test basenames from dist..."
            TEST_NAMES=$(find dist/apps/remix-ide-e2e/src/tests -type f \( -name "*.test.js" -o -name "*.spec.js" \) -print0 \
              | xargs -0 grep -IL "@disabled" \
              | xargs -I {} basename {} \
              | sed 's/\\.js$//' \
              | grep -v metamask)
            COUNT=$(printf '%s\n' "$TEST_NAMES" | wc -l | awk '{print $1}')
            echo "Found $COUNT enabled tests. Planning for << parameters.shards >> shard(s)."
            # Run planner once to produce a manifest with all bins
            printf '%s\n' "$TEST_NAMES" | node scripts/plan-shards.js --shards << parameters.shards >> --index 0 --timings timings-current.json --manifest-out reports/shards/manifest.json --verbose > /dev/null
            # Generate overview and per-shard file lists
            node -e '
              const fs = require("fs");
              const path = require("path");
              const outDir = path.join("reports","shards");
              const m = JSON.parse(fs.readFileSync(path.join(outDir, "manifest.json"), "utf8"));
              const bins = Array.isArray(m.bins) ? m.bins : [];
              // Build known/unknown stats using timings-current.json if present
              const timingsPath = "timings-current.json";
              let known = new Set();
              try {
                const t = JSON.parse(fs.readFileSync(timingsPath, "utf8"));
                for (const f of (t.files||[])) if (f && f.file) known.add(String(f.file).trim());
              } catch(_) {}
              let totalTests = 0, knownCount = 0, unknownCount = 0;
              bins.forEach(b => {
                const names = (b.items||[]).map(it => typeof it === "string" ? it : (it && it.name) || it).filter(Boolean);
                totalTests += names.length;
                names.forEach(n => { if (known.has(n)) knownCount++; else unknownCount++; });
              });
              const overview = bins.map((b,i)=>({ shard:i, count:(b.items||[]).length, totalSec:Number(b.total||0) }));
              const lines = overview.map(o=>`#${o.shard}\tcount=${o.count}\ttotal=${o.totalSec.toFixed(2)}s`);
              fs.writeFileSync(path.join(outDir, "overview.txt"), lines.join("\n")+"\n");
              fs.writeFileSync(path.join(outDir, "overview.json"), JSON.stringify({ shards: bins.length, overview, totals: bins.map(b=>b.total), counts: bins.map(b=>(b.items||[]).length), stats: { totalTests, knownCount, unknownCount } }, null, 2));
              bins.forEach((b,i)=>{
                const names = (b.items||[]).map(it => typeof it === "string" ? it : (it && it.name) || it).filter(Boolean);
                fs.writeFileSync(path.join(outDir, `files-${i}.txt`), names.join("\n") + (names.length?"\n":""));
              });
              console.log("Wrote overview.txt, overview.json and files-<i>.txt to", outDir);
            '
      - store_artifacts:
          path: ./reports/shards
      - store_artifacts:
          path: ./timings-current.json

  rerun-failed-e2e:
    docker:
      - image: cimg/node:20.19.0-browsers
    resource_class: << pipeline.parameters.resource_class >>
    working_directory: ~/remix-project
    parameters:
      history_limit:
        type: integer
        default: 5
      selection_mode:
        type: string
        default: "first-failed"
      workflow_name:
        type: string
        default: "web"
    steps:
      - checkout
      - attach_workspace:
          at: ~/remix-project
      - restore_cache:
          keys:
            - v1-deps-{{ checksum "yarn.lock" }}
      - run: yarn
      - run:
          name: Unpack dist from workspace
          command: |
            if [ -f remix-dist.tar.gz ]; then
              tar -xzf remix-dist.tar.gz
            fi
      - browser-tools/install-browser-tools:
          install-chrome: true
          install-chromedriver: false
          install-firefox: false
          install-geckodriver: false
      - run: yarn install_webdriver
      - run: google-chrome --version
      - run:
          name: Fetch failed tests from last run
          command: |
            if [ -n "${CIRCLECI_TOKEN:-}" ]; then
              node scripts/circleci-failed-tests.js --slug gh/remix-project-org/remix-project --workflow "<< parameters.workflow_name >>" --branch "${CIRCLE_BRANCH:-}" --jobs "remix-ide-browser" --limit << parameters.history_limit >> --mode "<< parameters.selection_mode >>" --verbose > failed-basenames.txt || true
            else
              echo "CIRCLECI_TOKEN not set; cannot fetch failed tests." > failed-basenames.txt
            fi
            echo "Failed list (raw):"; cat failed-basenames.txt || true
      - run:
          name: Rerun only failed tests
          command: |
            if [ ! -s failed-basenames.txt ]; then
              echo "No failing tests to rerun. Exiting."; exit 0; fi
            # Pass browser and workflow name; use pipeline parameter for retries
            E2E_RETRIES=<< pipeline.parameters.e2e_retries >> bash ./apps/remix-ide/ci/rerun_failed.sh chrome "<< parameters.workflow_name >>"
      - store_test_results:
          path: ./reports/tests
      - store_artifacts:
          path: ./reports/screenshots
      - store_artifacts:
          path: ./reports/failed

  post-failed-report:
    docker:
      - image: cimg/node:20.19.0-browsers
    resource_class: << pipeline.parameters.resource_class >>
    working_directory: ~/remix-project
    steps:
      - checkout
      - run:
          name: Install @octokit/auth-app for PR commenter
          command: |
            mkdir -p /tmp/pr-bot
            cd /tmp/pr-bot
            npm install --no-save @octokit/auth-app
      - run:
          name: Wait for E2E jobs to finish (success or fail)
          command: |
            if [ -z "${CIRCLECI_TOKEN:-}" ]; then
              echo "CIRCLECI_TOKEN not set; cannot poll CircleCI API. Skipping wait.";
            else
              # Set E2E job prefix - check if we're in rerun_failed workflow by checking job names
              echo "Checking workflow jobs to determine E2E prefix..."
              export E2E_JOB_PREFIX="remix-ide-browser,rerun-failed-e2e"
              echo "Will wait for jobs matching: $E2E_JOB_PREFIX"
              node scripts/wait-for-e2e-jobs.js;
            fi
      - run:
          name: Generate HTML failed report for this workflow
          command: |
            mkdir -p reports/ci-latest-failed
            # Just check all E2E job types - let the script filter what exists
            node scripts/generate-failed-report.js --workflow-id "$CIRCLE_WORKFLOW_ID" --jobs "remix-ide-browser,rerun-failed-e2e" --out reports/ci-latest-failed || true
      - store_artifacts:
          path: ./reports/ci-latest-failed
          destination: ci-latest-failed
      - run:
          name: Comment report link on PR (if failures)
          command: |
            NODE_PATH=/tmp/pr-bot/node_modules node scripts/post-pr-report.js reports/ci-latest-failed || true

  tests-passed:
    machine:
      image: default
    steps:
      - run: echo done

  remix-test-plugins:
    docker:
      - image: cimg/node:20.17.0-browsers
    resource_class: << pipeline.parameters.resource_class >>
    working_directory: ~/remix-project
    parameters:
      plugin:
        type: string
      parallelism:
        type: integer
        default: 1
    parallelism: << parameters.parallelism >>
    steps:
      - checkout
      - run: git fetch origin master:master || true
      - restore_cache:
          keys:
            - v1-deps-{{ checksum "yarn.lock" }}
      - run: yarn
      - nx-build-with-fallback:
          target: "<< parameters.plugin >>"
          config: "--configuration=production"
      - browser-tools/install-browser-tools:
          install-chrome: true
          install-chromedriver: false
          install-firefox: false
          install-geckodriver: false
      - run: yarn install_webdriver
      - run: google-chrome --version
      - run: ./apps/remix-ide/ci/browser_test_plugin.sh << parameters.plugin >>
      - store_test_results:
          path: ./reports/tests
      - store_artifacts:
          path: ./reports/screenshots

  predeploy:
    docker:
      - image: cimg/node:20.19.0-browsers
    resource_class: medium+
    working_directory: ~/remix-project
    steps:
      - checkout
      - restore_cache:
          keys:
            - v1-deps-{{ checksum "yarn.lock" }}
      - run: yarn
      - save_cache:
          key: v1-deps-{{ checksum "yarn.lock" }}
          paths:
            - node_modules
      - nx-build-with-fallback:
          target: "remix-ide"
          config: "--configuration=production"
          memory: "8192"
          fallback_command: "yarn build:production"

  deploy-build:
    docker:
      - image: cimg/node:20.19.0-browsers
    resource_class: medium+
    environment:
      COMMIT_AUTHOR_EMAIL: "yann@ethereum.org"
      COMMIT_AUTHOR: "Circle CI"
    working_directory: ~/remix-project
    parameters:
      script:
        type: string
    steps:
      - checkout
      - restore_cache:
          keys:
            - v1-deps-{{ checksum "yarn.lock" }}
      - run: yarn
      - save_cache:
          key: v1-deps-{{ checksum "yarn.lock" }}
          paths:
            - node_modules
      - nx-build-with-fallback:
          target: "remix-ide"
          config: "--configuration=production"
          memory: "8192"
          fallback_command: "yarn build:production"
      - run: ./apps/remix-ide/ci/deploy_from_travis_remix-<< parameters.script >>.sh

workflows:
  run_file_tests:
    when: << pipeline.parameters.run_file_tests >>
    jobs:
      - check-flaky-or-pr-tests:
          pattern: '<< pipeline.parameters.run_file_tests >>'
      - build:
          requires:
            - check-flaky-or-pr-tests
      - remix-ide-browser:
          requires:
            - build
          matrix:
            parameters:
              browser: ["chrome"]
              script: ["singletest.sh"]
              job: ["nogroup"]
              jobsize: ["1"]
              parallelism: [1]
              scriptparameter: ["<< pipeline.parameters.run_file_tests >>"]
              skip_timings: [true]
      - post-failed-report:
          requires:
            - build

  run_pr_tests:
    when: << pipeline.parameters.run_pr_tests >>
    jobs:
      - check-flaky-or-pr-tests:
          pattern: "\\.pr"
      - build:
          requires:
            - check-flaky-or-pr-tests
      - remix-ide-browser:
          requires:
            - build
          matrix:
            parameters:
              browser: ["chrome"]
              script: ["singletest.sh"]
              job: ["nogroup"]
              jobsize: ["1"]
              parallelism: [1]
              scriptparameter: ["\\.pr\\.js$"]
              skip_timings: [true]
      - post-failed-report:
          requires:
            - build

  run_flaky_tests:
    when: << pipeline.parameters.run_flaky_tests >>
    jobs:
      - check-flaky-or-pr-tests:
          pattern: "\\.flaky"
      - build:
          requires:
            - check-flaky-or-pr-tests
      - remix-ide-browser:
          requires:
            - build
          matrix:
            parameters:
              browser: ["chrome"]
              script: ["singletest.sh"]
              job: ["nogroup"]
              jobsize: ["1"]
              parallelism: [5]
              scriptparameter: ["\\.flaky"]
              skip_timings: [true]
      - post-failed-report:
          requires:
            - build

  web:
    when: << pipeline.parameters.run_all_tests >>
    jobs:
      - build
      - build-plugin:
          matrix:
            parameters:
              plugin: ["plugin_api"]
      - lint:
          requires:
            - build
      - remix-libs
      - remix-test-plugins:
          name: test-plugin-<< matrix.plugin >>
          requires:
            - build
            - build-plugin
          matrix:
            alias: plugins
            parameters:
              plugin: ["plugin_api"]
              parallelism: [1, 9]
            exclude:
              - plugin: plugin_api
                parallelism: 1
      - remix-ide-browser:
          requires:
            - build
          matrix:
            alias: chrome-tests
            parameters:
              browser: ["chrome"]
              script: ["browser_test.sh"]
              job: ["nogroup"]
              jobsize: ["1"]
              parallelism: [1]
              scriptparameter: [""]
              shard_index: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]
              vertical_mode: [true]
      - tests-passed:
          requires:
            - lint
            - remix-libs
            - chrome-tests
            - plugins
      - post-failed-report:
          requires:
            - build

  lint_only:
    when: << pipeline.parameters.run_lint_only >>
    jobs:
      - lint

  build_only:
    when: << pipeline.parameters.run_build_only >>
    jobs:
      - build

  plan_e2e_shards:
    when: << pipeline.parameters.run_plan_shards >>
    jobs:
      - plan-e2e-shards:
          name: plan-e2e-shards
          shards: << pipeline.parameters.e2e_parallelism >>

  rerun_failed:
    when: << pipeline.parameters.run_rerun_failed >>
    jobs:
      - build
      - rerun-failed-e2e:
          requires:
            - build
          history_limit: << pipeline.parameters.rerun_failed_history >>
          selection_mode: << pipeline.parameters.rerun_failed_mode >>
          workflow_name: << pipeline.parameters.rerun_failed_workflow >>
      - post-failed-report:
          requires:
            - build
